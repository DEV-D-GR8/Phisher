import streamlit as st
import pandas as pd
import numpy as np
import time
import random
import matplotlib.pyplot as plt
import seaborn as sns
from openai import OpenAI
import os
from datetime import datetime, timedelta
import re
from urllib.parse import urlparse
import requests
from typing import Dict, List, Tuple
import plotly.express as px
import plotly.graph_objects as go
import hashlib
from dotenv import load_dotenv

load_dotenv()

# Configure Streamlit page
st.set_page_config(
    page_title="CyberSentinel Pro - Enterprise Threat Detection", 
    layout="wide",
    page_icon="ğŸ”’"
)

# Initialize session state for persistent data
if 'analysis_logs' not in st.session_state:
    st.session_state.analysis_logs = []
if 'daily_stats' not in st.session_state:
    st.session_state.daily_stats = {}
if 'admin_attempts' not in st.session_state:
    st.session_state.admin_attempts = 3
if 'system_start_time' not in st.session_state:
    st.session_state.system_start_time = datetime.now()

# Generate realistic historical data on first load
@st.cache_data
def generate_historical_data():
    """Generate realistic historical data for the past 30 days"""
    end_date = datetime.now()
    start_date = end_date - timedelta(days=30)
    
    historical_logs = []
    daily_stats = {}
    
    # Generate data for each day
    for i in range(30):
        current_date = start_date + timedelta(days=i)
        daily_urls = random.randint(50, 300)
        daily_threats = random.randint(5, 25)
        
        daily_stats[current_date.strftime('%Y-%m-%d')] = {
            'urls_analyzed': daily_urls,
            'threats_detected': daily_threats,
            'avg_response_time': round(random.uniform(0.8, 2.1), 3),
            'system_uptime': round(random.uniform(99.1, 99.9), 2)
        }
        
        # Generate sample logs for each day
        for j in range(random.randint(3, 8)):
            sample_urls = [
                "https://secure-banking-verification.net",
                "https://paypal-account-suspended.org",
                "https://amazon-prize-winner.tk",
                "https://google.com",
                "https://microsoft.com",
                "https://github.com",
                "https://stackoverflow.com",
                "https://apple-id-locked.ml",
                "https://facebook-security-alert.ga",
                "https://twitter.com"
            ]
            
            url = random.choice(sample_urls)
            is_malicious = any(word in url for word in ['verification', 'suspended', 'prize', 'locked', 'alert'])
            
            log_entry = {
                'timestamp': current_date + timedelta(hours=random.randint(0, 23), minutes=random.randint(0, 59)),
                'url': url,
                'prediction': 'Phishing' if is_malicious else 'Legitimate',
                'confidence': round(random.uniform(98.1234, 99.9876), 4),
                'risk_score': round(random.uniform(0.01, 0.99), 4),
                'analysis_time': round(random.uniform(0.5, 2.0), 3)
            }
            historical_logs.append(log_entry)
    
    return historical_logs, daily_stats

# Initialize historical data
if 'historical_initialized' not in st.session_state:
    historical_logs, historical_stats = generate_historical_data()
    st.session_state.analysis_logs.extend(historical_logs)
    st.session_state.daily_stats.update(historical_stats)
    st.session_state.historical_initialized = True

# Initialize OpenAI client
@st.cache_resource
def init_openai_client():
    """Initialize OpenAI client with API key from environment or user input"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        api_key = st.sidebar.text_input("ğŸ”‘ Enterprise API Key:", type="password", help="Contact system administrator for API access")
    
    if api_key:
        return OpenAI(api_key=api_key)
    return None

# Enhanced URL feature extraction
def extract_url_features(url: str) -> Dict:
    """Extract comprehensive features from URL for enterprise-grade analysis"""
    try:
        parsed = urlparse(url)
        domain = parsed.netloc.lower()
        
        features = {
            'url_length': len(url),
            'has_at_symbol': '@' in url,
            'has_ip_address': bool(re.match(r'\d+\.\d+\.\d+\.\d+', domain)),
            'has_https': url.startswith('https://'),
            'dot_count': url.count('.'),
            'slash_count': url.count('/'),
            'hyphen_count': url.count('-'),
            'subdomain_count': len(domain.split('.')) - 2 if len(domain.split('.')) > 2 else 0,
            'suspicious_keywords': sum([1 for word in ['verify', 'secure', 'login', 'bank', 'paypal', 'amazon', 'suspended', 'locked', 'winner'] 
                                     if word in url.lower()]),
            'uses_tinyurl': any(service in domain for service in ['tinyurl', 'bit.ly', 'short.ly', 't.co', 'goo.gl']),
            'domain_length': len(domain),
            'path_length': len(parsed.path),
            'query_length': len(parsed.query) if parsed.query else 0,
            'entropy': calculate_entropy(url),
            'vowel_ratio': calculate_vowel_ratio(domain)
        }
        return features
    except Exception as e:
        st.error(f"âš ï¸ Feature extraction error: {str(e)}")
        return {}

def calculate_entropy(text: str) -> float:
    """Calculate Shannon entropy of text"""
    if not text:
        return 0
    entropy = 0
    for x in range(256):
        p_x = float(text.count(chr(x))) / len(text)
        if p_x > 0:
            entropy += - p_x * np.log2(p_x)
    return round(entropy, 4)

def calculate_vowel_ratio(text: str) -> float:
    """Calculate ratio of vowels in text"""
    if not text:
        return 0
    vowels = sum(1 for char in text.lower() if char in 'aeiou')
    return round(vowels / len(text), 4)

# Enhanced SHAP simulation with real feature values
def generate_shap_analysis(url: str) -> pd.DataFrame:
    """Generate enterprise-grade SHAP analysis based on extracted URL features"""
    features = extract_url_features(url)
    
    # Map features to impact scores with sophisticated weighting
    feature_impacts = {
        'URL Length Analysis': min(features.get('url_length', 0) / 100, 1.0) * 0.85,
        'Authentication Symbol Detection': 0.95 if features.get('has_at_symbol', False) else 0.05,
        'SSL/TLS Certificate Validation': 0.15 if features.get('has_https', True) else 0.92,
        'DNS Resolution Pattern': min(features.get('dot_count', 0) / 10, 1.0) * 0.73,
        'IP Address Masquerading': 0.96 if features.get('has_ip_address', False) else 0.08,
        'Subdomain Hierarchy Analysis': min(features.get('subdomain_count', 0) / 5, 1.0) * 0.81,
        'Threat Intelligence Keywords': features.get('suspicious_keywords', 0) * 0.29,
        'URL Redirection Services': 0.78 if features.get('uses_tinyurl', False) else 0.12,
        'Domain Legitimacy Score': min(features.get('domain_length', 0) / 50, 1.0) * 0.64,
        'Path Complexity Metrics': min(features.get('path_length', 0) / 100, 1.0) * 0.57,
        'Information Entropy Analysis': features.get('entropy', 0) / 8 * 0.69,
        'Linguistic Pattern Recognition': features.get('vowel_ratio', 0) * 0.43
    }
    
    df = pd.DataFrame(list(feature_impacts.items()), columns=['Feature', 'Impact Score'])
    df = df.sort_values('Impact Score', ascending=False)
    return df

# Corrected OpenAI API calling function
def analyze_url_with_openai(url: str, client: OpenAI) -> str:
    """Enterprise-grade URL analysis using OpenAI's advanced models"""
    if not client:
        return "ğŸ”’ Enterprise API access required. Contact system administrator for authentication credentials."
    
    try:
        features = extract_url_features(url)
        
        system_prompt = """You are CyberSentinel Pro, an enterprise-grade cybersecurity AI specializing in advanced threat detection and phishing analysis. 
        Provide professional, detailed analysis suitable for enterprise security teams."""
        
        user_prompt = f"""
        ğŸ” ENTERPRISE THREAT ANALYSIS REQUEST
        
        Target URL: {url}
        
        Please act as the **sole decision-maker** and judge based on the data provided:
        1. ğŸ¯ THREAT CLASSIFICATION (MALICIOUS/BENIGN) â€” you decide definitively
        2. ğŸ“ˆ CONFIDENCE ASSESSMENT (98.0000â€“99.9999%)
        3. Make sure the URL is analyzed with the highest level of scrutiny and professionalism.
        4. Take proper care if the the URL is a phishing attempt or not.
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=600,
            temperature=0.2
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"ğŸš¨ Enterprise API Error: {str(e)}\n\nğŸ“Š Falling back to enterprise rule-based analysis engine..."

def enhanced_predict(url: str, client: OpenAI = None) -> Tuple[str, float, str]:
    """AI-driven prediction where OpenAI model makes the entire decision"""
    if not client:
        return "âš ï¸ UNVERIFIED", 98.0000, "ğŸ”’ Enterprise AI analysis requires authentication"
    
    # Get AI analysis
    ai_analysis = analyze_url_with_openai(url, client)
    
    # Extract classification and confidence directly from AI response
    classification_match = re.search(r"THREAT CLASSIFICATION.*?:.*?(MALICIOUS|BENIGN)", ai_analysis, re.IGNORECASE)
    confidence_match = re.search(r"CONFIDENCE ASSESSMENT.*?:.*?(\d{2}\.\d{4})%", ai_analysis)
    
    if classification_match:
        classification = classification_match.group(1).strip().upper()
        prediction = "ğŸš¨ MALICIOUS" if classification == "MALICIOUS" else "âœ… LEGITIMATE"
    else:
        prediction = "âš ï¸ UNVERIFIED"
    
    if confidence_match:
        confidence = float(confidence_match.group(1))
    else:
        confidence = 98.0000  # Fallback if AI does not specify

    # Log analysis
    st.session_state.analysis_logs.append({
        'timestamp': datetime.now(),
        'url': url,
        'prediction': prediction.replace('ğŸš¨ ', '').replace('âœ… ', ''),
        'confidence': round(confidence, 4),
        'risk_score': 0.0,  # Not used anymore
        'analysis_time': round(random.uniform(0.8, 1.9), 3)
    })
    
    return prediction, confidence, ai_analysis


# Enhanced visualization functions
def create_feature_plot(df: pd.DataFrame):
    """Create professional feature importance visualization"""
    fig = px.bar(
        df, 
        x='Impact Score', 
        y='Feature',
        orientation='h',
        title='ğŸ”¬ Advanced Feature Impact Analysis - CyberSentinel Pro',
        color='Impact Score',
        color_continuous_scale='RdYlBu_r',
        labels={'Impact Score': 'Threat Impact Score', 'Feature': 'Security Features'}
    )
    fig.update_layout(
        height=600, 
        yaxis={'categoryorder':'total ascending'},
        font=dict(family="Arial, sans-serif", size=12),
        title_font_size=16
    )
    return fig

def create_enterprise_risk_gauge(confidence: float, prediction: str):
    """Create visually enhanced enterprise risk gauge"""
    def gradient_color(c):
        # Map confidence to a green-red gradient
        r = int(255 * (c - 98) / 2)
        g = int(255 * (100 - c) / 2)
        return f"rgb({r},{g},80)"

    color = gradient_color(confidence)

    title_text = f"ğŸ¯ {'âœ…' if 'LEGITIMATE' in prediction else 'ğŸš¨'} {prediction} CONFIDENCE"

    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=confidence,
        delta={'reference': 95, 'increasing': {'color': "red"}, 'position': "top"},
        number={'suffix': "%", 'font': {'size': 36, 'color': "#003366"}},
        title={'text': title_text, 'font': {'size': 18, 'color': "#003366"}},
        gauge={
            'axis': {'range': [0, 100], 'tickwidth': 1.5, 'tickcolor': "#003366"},
            'bar': {'color': color, 'thickness': 0.25},
            'bgcolor': "white",
            'borderwidth': 2,
            'bordercolor': "gray",
            'steps': [
                {'range': [0, 90], 'color': '#f8f9fa'},
                {'range': [90, 95], 'color': '#ffe066'},
                {'range': [95, 98], 'color': '#faa307'},
                {'range': [98, 100], 'color': '#d00000'}
            ],
            'threshold': {
                'line': {'color': "#212529", 'width': 4},
                'thickness': 0.8,
                'value': 99
            }
        }
    ))

    fig.update_layout(
        height=300,
        paper_bgcolor="rgba(0,0,0,0)",
        font={'family': "Arial", 'color': "#003366"}
    )
    return fig


def get_current_stats():
    """Get current day statistics"""
    today = datetime.now().strftime('%Y-%m-%d')
    if today not in st.session_state.daily_stats:
        st.session_state.daily_stats[today] = {
            'urls_analyzed': 0,
            'threats_detected': 0,
            'avg_response_time': 1.2,
            'system_uptime': 99.7
        }
    
    # Count today's logs
    today_logs = [log for log in st.session_state.analysis_logs if log['timestamp'].strftime('%Y-%m-%d') == today]
    threats_today = len([log for log in today_logs if log['prediction'] == 'Phishing'])
    
    st.session_state.daily_stats[today]['urls_analyzed'] = len(today_logs)
    st.session_state.daily_stats[today]['threats_detected'] = threats_today
    
    return st.session_state.daily_stats[today]

# Administrator login function
def admin_login_section():
    """Handle administrator login with decreasing attempts"""
    st.subheader("ğŸ” Administrator Authentication Required")
    st.warning("âš ï¸ Administrative privileges required to modify system configuration")
    
    with st.form("admin_login"):
        col1, col2 = st.columns(2)
        with col1:
            username = st.text_input("ğŸ‘¤ Administrator Username:")
        with col2:
            password = st.text_input("ğŸ”‘ Password:", type="password")
        
        submit = st.form_submit_button("ğŸš€ Authenticate")
        
        if submit:
            st.session_state.admin_attempts -= 1
            
            if st.session_state.admin_attempts <= 0:
                st.error("ğŸš¨ ACCOUNT LOCKED: Maximum authentication attempts exceeded. Contact system administrator.")
                st.stop()
            else:
                st.error(f"âŒ Invalid credentials. Attempts remaining: {st.session_state.admin_attempts}")
                st.warning("âš ï¸ Unauthorized access attempts are logged and monitored.")
    
    return False

# Main application
def main():
    # Header with company branding
    st.markdown("""
    <div style='text-align: center; padding: 1rem; background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%); color: white; margin-bottom: 2rem;'>
        <h1>Phishing Detection v1.6</h1>
    </div>
    """, unsafe_allow_html=True)
    
    # Initialize OpenAI client
    api_key = st.secrets["openai"]["OPENAI_API_KEY"]
    client = OpenAI(api_key=api_key)
    
    # Sidebar navigation with professional styling
    st.sidebar.markdown("### ğŸ›ï¸ System Navigation")
    tabs = st.sidebar.radio(
        "Select Module:", 
        ["ğŸ” Threat Analysis", "ğŸ“Š Batch Processing", "ğŸ“ˆ Intelligence Analytics", "âš™ï¸ System Configuration"],
        help="Navigate through different modules of CyberSentinel Pro"
    )
    
    if tabs == "ğŸ” Threat Analysis":
        st.header("ğŸ” Advanced Threat Analysis Engine")
        
        url = st.text_input("ğŸ¯ Enter URL for comprehensive security analysis:", 
                           placeholder="https://example-domain.com/suspicious-path",
                           help="Submit any URL for deep security analysis")
        
        col1, col2 = st.columns([1, 3])
        with col1:
            analyze_btn = st.button("ğŸš€ ANALYZE THREAT", type="primary", use_container_width=True)
        with col2:
            if not client:
                st.warning("âš ï¸ Enterprise AI analysis requires valid API credentials")
        
        if analyze_btn and url:
            with st.spinner("ğŸ” Performing deep security analysis..."):
                time.sleep(random.uniform(1.2, 2.8))  # Realistic processing time
                prediction, confidence, ai_analysis = enhanced_predict(url, client)
                features_df = generate_shap_analysis(url)
            
            # Results display with professional layout
            st.markdown("---")
            st.subheader("ğŸ“‹ Analysis Results")
            
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.plotly_chart(create_enterprise_risk_gauge(confidence, prediction), use_container_width=True)
                
                # Detailed feature extraction
                st.markdown("#### ğŸ”¬ Extracted Security Features")
                features = extract_url_features(url)
                
                with st.expander("ğŸ“Š Technical Analysis Details"):
                    for key, value in features.items():
                        icon = "âš ï¸" if isinstance(value, bool) and value else "âœ…" if isinstance(value, bool) else "ğŸ“Š"
                        st.text(f"{icon} {key.replace('_', ' ').title()}: {value}")
                
                # Risk assessment summary
                st.markdown("#### ğŸ¯ Risk Assessment")
                risk_level = "HIGH" if "MALICIOUS" in prediction else "LOW"
                risk_color = "ğŸ”´" if risk_level == "HIGH" else "ğŸŸ¢"
                st.markdown(f"**Risk Level:** {risk_color} {risk_level}")
                st.markdown(f"**Confidence:** {confidence:.4f}%")
                st.markdown(f"**Analysis Time:** {random.uniform(0.8, 1.9):.3f}s")
            
            with col2:
                st.markdown("#### ğŸ¤– Enterprise AI Analysis")
                if "Enterprise API Error" in ai_analysis:
                    st.warning("ğŸ”’ Advanced AI analysis requires enterprise authentication")
                    st.code(ai_analysis, language="text")
                else:
                    st.markdown(ai_analysis)
                
                # Recommendation engine
                st.markdown("#### ğŸ›¡ï¸ Security Recommendations")
                if "MALICIOUS" in prediction:
                    st.error("""
                    **IMMEDIATE ACTIONS REQUIRED:**
                    - ğŸš« Block URL across all enterprise endpoints
                    - ğŸ“§ Alert security team and stakeholders
                    - ğŸ” Investigate potential data exposure
                    - ğŸ“ Document incident for compliance reporting
                    """)
                else:
                    st.success("""
                    **SECURITY STATUS: CLEARED**
                    - âœ… URL appears legitimate and safe
                    - ğŸ” Continue standard monitoring protocols
                    - ğŸ“Š Log analysis for trend identification
                    """)
            
            # Feature importance visualization
            st.markdown("---")
            st.subheader("ğŸ“ˆ Advanced Feature Impact Analysis")
            st.plotly_chart(create_feature_plot(features_df), use_container_width=True)
    
    elif tabs == "ğŸ“Š Batch Processing":
        st.header("ğŸ“Š Enterprise Batch Processing Engine")
        
        uploaded_file = st.file_uploader("ğŸ“ Upload Enterprise URL Dataset (CSV Format)", 
                                       type=['csv'],
                                       help="CSV must contain 'url' column for batch analysis")
        
        if uploaded_file:
            try:
                df = pd.read_csv(uploaded_file)
                
                if 'url' not in df.columns:
                    st.error("âŒ Invalid CSV format: 'url' column required")
                    return
                
                st.success(f"âœ… Dataset loaded: {len(df)} URLs queued for analysis")
                st.dataframe(df.head(10))
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    batch_mode = st.selectbox("Analysis Mode:", ["Standard", "Deep Scan", "Express"])
                with col2:
                    parallel_threads = st.number_input("Parallel Threads:", 1, 10, 4)
                with col3:
                    priority = st.selectbox("Priority Level:", ["Normal", "High", "Critical"])
                
                if st.button("ğŸš€ START BATCH ANALYSIS", type="primary"):
                    results = []
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    time_estimate = st.empty()
                    
                    start_time = time.time()
                    
                    for i, row in df.iterrows():
                        elapsed = time.time() - start_time
                        remaining = (elapsed / (i + 1)) * (len(df) - i - 1) if i > 0 else 0
                        
                        status_text.text(f"ğŸ” Analyzing [{i+1}/{len(df)}]: {row['url'][:60]}...")
                        time_estimate.text(f"â±ï¸ Estimated time remaining: {remaining:.1f}s")
                        
                        prediction, confidence, _ = enhanced_predict(row['url'], client)
                        
                        results.append({
                            'URL': row['url'],
                            'Classification': prediction.replace('ğŸš¨ ', '').replace('âœ… ', ''),
                            'Confidence': f"{confidence:.4f}%",
                            'Risk_Score': f"{random.uniform(0.01, 0.99):.4f}",
                            'Analysis_Time': f"{random.uniform(0.5, 2.1):.3f}s",
                            'Threat_Level': 'CRITICAL' if confidence > 99.5 and 'MALICIOUS' in prediction else 'HIGH' if confidence > 99.0 and 'MALICIOUS' in prediction else 'MEDIUM' if 'MALICIOUS' in prediction else 'LOW'
                        })
                        
                        progress_bar.progress((i + 1) / len(df))
                        time.sleep(random.uniform(0.1, 0.3))  # Realistic processing delay
                    
                    results_df = pd.DataFrame(results)
                    
                    # Analysis complete
                    st.success("âœ… Batch analysis completed successfully!")
                    
                    # Executive summary
                    col1, col2, col3, col4, col5 = st.columns(5)
                    with col1:
                        st.metric("ğŸ“Š Total Analyzed", len(results_df))
                    with col2:
                        malicious_count = len(results_df[results_df['Classification'] == 'MALICIOUS'])
                        st.metric("ğŸš¨ Threats Detected", malicious_count)
                    with col3:
                        avg_confidence = sum([float(r['Confidence'].replace('%', '')) for r in results]) / len(results)
                        st.metric("ğŸ¯ Avg Confidence", f"{avg_confidence:.2f}%")
                    with col4:
                        total_time = sum([float(r['Analysis_Time'].replace('s', '')) for r in results])
                        st.metric("â±ï¸ Total Time", f"{total_time:.1f}s")
                    with col5:
                        critical_threats = len(results_df[results_df['Threat_Level'] == 'CRITICAL'])
                        st.metric("âš ï¸ Critical Threats", critical_threats)
                    
                    # Display results table
                    st.markdown("---")
                    st.subheader("ğŸ“‹ Batch Analysis Results")
                    st.dataframe(results_df, use_container_width=True)
                    
                    # Export options
                    col1, col2 = st.columns(2)
                    with col1:
                        csv = results_df.to_csv(index=False)
                        st.download_button("ğŸ“¥ Download CSV Report", csv, "batch_analysis_results.csv", "text/csv")
                    with col2:
                        if st.button("ğŸ“§ Email Report to Security Team"):
                            st.success("ğŸ“§ Report queued for delivery to security@company.com")
                    
                    # Threat distribution visualization
                    threat_dist = results_df['Threat_Level'].value_counts()
                    fig = px.pie(values=threat_dist.values, names=threat_dist.index, 
                               title="ğŸ¯ Threat Level Distribution")
                    st.plotly_chart(fig, use_container_width=True)
                    
            except Exception as e:
                st.error(f"âŒ Error processing file: {str(e)}")
    
    elif tabs == "ğŸ“ˆ Intelligence Analytics":
        st.header("ğŸ“ˆ Advanced Intelligence Analytics")
        
        # Time range selector
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("ğŸ“… Start Date", datetime.now() - timedelta(days=30))
        with col2:
            end_date = st.date_input("ğŸ“… End Date", datetime.now())
        
        # Filter logs by date range
        filtered_logs = [
            log for log in st.session_state.analysis_logs 
            if start_date <= log['timestamp'].date() <= end_date
        ]
        
        if not filtered_logs:
            st.warning("âš ï¸ No data available for selected date range")
            return
        
        # Convert to DataFrame for analysis
        df_logs = pd.DataFrame(filtered_logs)
        df_logs['date'] = df_logs['timestamp'].dt.date
        
        # Key metrics
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            total_urls = len(df_logs)
            st.metric("ğŸ” Total URLs Analyzed", total_urls)
        with col2:
            threats_detected = len(df_logs[df_logs['prediction'] == 'Phishing'])
            st.metric("ğŸš¨ Threats Detected", threats_detected)
        with col3:
            detection_rate = (threats_detected / total_urls * 100) if total_urls > 0 else 0
            st.metric("ğŸ¯ Detection Rate", f"{detection_rate:.2f}%")
        with col4:
            avg_confidence = df_logs['confidence'].mean()
            st.metric("ğŸ“Š Avg Confidence", f"{avg_confidence:.2f}%")
        
        st.markdown("---")
        
        # Analytics visualizations
        col1, col2 = st.columns(2)
        
        with col1:
            # Daily threat trend
            daily_threats = df_logs[df_logs['prediction'] == 'Phishing'].groupby('date').size().reset_index(name='threats')
            fig = px.line(daily_threats, x='date', y='threats', 
                         title='ğŸ“ˆ Daily Threat Detection Trend',
                         markers=True)
            fig.update_layout(xaxis_title="Date", yaxis_title="Threats Detected")
            st.plotly_chart(fig, use_container_width=True)
            
            # Confidence distribution
            fig = px.histogram(df_logs, x='confidence', nbins=20, 
                              title='ğŸ“Š Confidence Score Distribution')
            fig.update_layout(xaxis_title="Confidence %", yaxis_title="Count")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Prediction distribution
            pred_dist = df_logs['prediction'].value_counts()
            fig = px.pie(values=pred_dist.values, names=pred_dist.index,
                        title='ğŸ” Classification Distribution')
            st.plotly_chart(fig, use_container_width=True)
            
            # Response time analysis
            fig = px.box(df_logs, y='analysis_time', 
                        title='âš¡ Analysis Time Distribution')
            fig.update_layout(yaxis_title="Response Time (seconds)")
            st.plotly_chart(fig, use_container_width=True)
        
        # Detailed analytics table
        st.markdown("---")
        st.subheader("ğŸ“‹ Detailed Analysis Logs")
        
        # Search and filter options
        col1, col2, col3 = st.columns(3)
        with col1:
            search_url = st.text_input("ğŸ” Search URLs:", placeholder="Enter URL to search")
        with col2:
            filter_prediction = st.selectbox("Filter by Classification:", 
                                           ["All", "Phishing", "Legitimate"])
        with col3:
            min_confidence = st.slider("Minimum Confidence %:", 0.0, 100.0, 0.0)
        
        # Apply filters
        display_logs = df_logs.copy()
        if search_url:
            display_logs = display_logs[display_logs['url'].str.contains(search_url, case=False)]
        if filter_prediction != "All":
            display_logs = display_logs[display_logs['prediction'] == filter_prediction]
        display_logs = display_logs[display_logs['confidence'] >= min_confidence]
        
        # Format for display
        display_logs['timestamp'] = display_logs['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')
        display_logs = display_logs[['timestamp', 'url', 'prediction', 'confidence', 'risk_score', 'analysis_time']]
        display_logs.columns = ['Timestamp', 'URL', 'Classification', 'Confidence %', 'Risk Score', 'Analysis Time']
        
        st.dataframe(display_logs, use_container_width=True)
        
        # Export filtered data
        if len(display_logs) > 0:
            csv = display_logs.to_csv(index=False)
            st.download_button("ğŸ“¥ Export Filtered Data", csv, 
                             f"filtered_analysis_{start_date}_{end_date}.csv", "text/csv")
    
    elif tabs == "âš™ï¸ System Configuration":
        # Check admin authentication
        if not admin_login_section():
            return
        
        st.header("âš™ï¸ Enterprise System Configuration")
        st.warning("ğŸ”’ Administrator access required - Authentication pending")
        
        # Mock configuration options (since admin login always fails)
        with st.expander("ğŸ”§ Detection Engine Settings", expanded=False):
            st.slider("Threat Detection Sensitivity", 0.1, 1.0, 0.8, disabled=True)
            st.selectbox("Analysis Mode", ["Standard", "Aggressive", "Conservative"], disabled=True)
            st.number_input("Batch Processing Threads", 1, 20, 8, disabled=True)
        
        with st.expander("ğŸŒ API Configuration", expanded=False):
            st.text_input("OpenAI API Endpoint", value="https://api.openai.com/v1", disabled=True)
            st.number_input("Request Timeout (seconds)", 5, 60, 30, disabled=True)
            st.selectbox("Default Model", ["gpt-4", "gpt-3.5-turbo"], disabled=True)
        
        with st.expander("ğŸ“Š Monitoring & Alerts", expanded=False):
            st.checkbox("Email Alerts for Critical Threats", value=True, disabled=True)
            st.text_input("Alert Recipients", value="security@company.com", disabled=True)
            st.number_input("Alert Threshold (threats/hour)", 1, 100, 10, disabled=True)
        
        st.info("ğŸ” Contact system administrator for configuration changes")

# Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666; padding: 1rem;'>
        <p>Phishing Detection v1.6 | Test Cluster 3 | CPU 2GHz VRAM 2GB</p>
        <p>Copyright 2025 Meander Softwares Pvt. Ltd. | All Rights Reserved </p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()