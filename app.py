import streamlit as st
import pandas as pd
import numpy as np
import time
import random
import matplotlib.pyplot as plt
import seaborn as sns
from openai import OpenAI
import os
from datetime import datetime, timedelta
import re
from urllib.parse import urlparse
import requests
from typing import Dict, List, Tuple
import plotly.express as px
import plotly.graph_objects as go
import hashlib
from dotenv import load_dotenv

load_dotenv()

# Configure Streamlit page
st.set_page_config(
    page_title="CyberSentinel Pro - Enterprise Threat Detection", 
    layout="wide",
    page_icon="üîí"
)

# Initialize session state for persistent data
if 'analysis_logs' not in st.session_state:
    st.session_state.analysis_logs = []
if 'daily_stats' not in st.session_state:
    st.session_state.daily_stats = {}
if 'admin_attempts' not in st.session_state:
    st.session_state.admin_attempts = 3
if 'system_start_time' not in st.session_state:
    st.session_state.system_start_time = datetime.now()

# Generate realistic historical data on first load
@st.cache_data
def generate_historical_data():
    """Generate realistic historical data for the past 30 days"""
    end_date = datetime.now()
    start_date = end_date - timedelta(days=30)
    
    historical_logs = []
    daily_stats = {}
    
    # Generate data for each day
    for i in range(30):
        current_date = start_date + timedelta(days=i)
        daily_urls = random.randint(50, 300)
        daily_threats = random.randint(5, 25)
        
        daily_stats[current_date.strftime('%Y-%m-%d')] = {
            'urls_analyzed': daily_urls,
            'threats_detected': daily_threats,
            'avg_response_time': round(random.uniform(0.8, 2.1), 3),
            'system_uptime': round(random.uniform(99.1, 99.9), 2)
        }
        
        # Generate sample logs for each day
        for j in range(random.randint(3, 8)):
            sample_urls = [
                "https://secure-banking-verification.net",
                "https://paypal-account-suspended.org",
                "https://amazon-prize-winner.tk",
                "https://google.com",
                "https://microsoft.com",
                "https://github.com",
                "https://stackoverflow.com",
                "https://apple-id-locked.ml",
                "https://facebook-security-alert.ga",
                "https://twitter.com"
            ]
            
            url = random.choice(sample_urls)
            is_malicious = any(word in url for word in ['verification', 'suspended', 'prize', 'locked', 'alert'])
            
            log_entry = {
                'timestamp': current_date + timedelta(hours=random.randint(0, 23), minutes=random.randint(0, 59)),
                'url': url,
                'prediction': 'Phishing' if is_malicious else 'Legitimate',
                'confidence': round(random.uniform(98.1234, 99.9876), 4),
                'risk_score': round(random.uniform(0.01, 0.99), 4),
                'analysis_time': round(random.uniform(0.5, 2.0), 3)
            }
            historical_logs.append(log_entry)
    
    return historical_logs, daily_stats

# Initialize historical data
if 'historical_initialized' not in st.session_state:
    historical_logs, historical_stats = generate_historical_data()
    st.session_state.analysis_logs.extend(historical_logs)
    st.session_state.daily_stats.update(historical_stats)
    st.session_state.historical_initialized = True

# Initialize OpenAI client
@st.cache_resource
def init_openai_client():
    """Initialize OpenAI client with API key from environment or user input"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        api_key = st.sidebar.text_input("üîë Enterprise API Key:", type="password", help="Contact system administrator for API access")
    
    if api_key:
        return OpenAI(api_key=api_key)
    return None

# Enhanced URL feature extraction
def extract_url_features(url: str) -> Dict:
    """Extract comprehensive features from URL for enterprise-grade analysis"""
    try:
        parsed = urlparse(url)
        domain = parsed.netloc.lower()
        
        features = {
            'url_length': len(url),
            'has_at_symbol': '@' in url,
            'has_ip_address': bool(re.match(r'\d+\.\d+\.\d+\.\d+', domain)),
            'has_https': url.startswith('https://'),
            'dot_count': url.count('.'),
            'slash_count': url.count('/'),
            'hyphen_count': url.count('-'),
            'subdomain_count': len(domain.split('.')) - 2 if len(domain.split('.')) > 2 else 0,
            'suspicious_keywords': sum([1 for word in ['verify', 'secure', 'login', 'bank', 'paypal', 'amazon', 'suspended', 'locked', 'winner'] 
                                     if word in url.lower()]),
            'uses_tinyurl': any(service in domain for service in ['tinyurl', 'bit.ly', 'short.ly', 't.co', 'goo.gl']),
            'domain_length': len(domain),
            'path_length': len(parsed.path),
            'query_length': len(parsed.query) if parsed.query else 0,
            'entropy': calculate_entropy(url),
            'vowel_ratio': calculate_vowel_ratio(domain)
        }
        return features
    except Exception as e:
        st.error(f"‚ö†Ô∏è Feature extraction error: {str(e)}")
        return {}

def calculate_entropy(text: str) -> float:
    """Calculate Shannon entropy of text"""
    if not text:
        return 0
    entropy = 0
    for x in range(256):
        p_x = float(text.count(chr(x))) / len(text)
        if p_x > 0:
            entropy += - p_x * np.log2(p_x)
    return round(entropy, 4)

def calculate_vowel_ratio(text: str) -> float:
    """Calculate ratio of vowels in text"""
    if not text:
        return 0
    vowels = sum(1 for char in text.lower() if char in 'aeiou')
    return round(vowels / len(text), 4)

# Enhanced SHAP simulation with real feature values
def generate_shap_analysis(url: str) -> pd.DataFrame:
    """Generate enterprise-grade SHAP analysis based on extracted URL features"""
    features = extract_url_features(url)
    
    # Map features to impact scores with sophisticated weighting
    feature_impacts = {
        'URL Length Analysis': min(features.get('url_length', 0) / 100, 1.0) * 0.85,
        'Authentication Symbol Detection': 0.95 if features.get('has_at_symbol', False) else 0.05,
        'SSL/TLS Certificate Validation': 0.15 if features.get('has_https', True) else 0.92,
        'DNS Resolution Pattern': min(features.get('dot_count', 0) / 10, 1.0) * 0.73,
        'IP Address Masquerading': 0.96 if features.get('has_ip_address', False) else 0.08,
        'Subdomain Hierarchy Analysis': min(features.get('subdomain_count', 0) / 5, 1.0) * 0.81,
        'Threat Intelligence Keywords': features.get('suspicious_keywords', 0) * 0.29,
        'URL Redirection Services': 0.78 if features.get('uses_tinyurl', False) else 0.12,
        'Domain Legitimacy Score': min(features.get('domain_length', 0) / 50, 1.0) * 0.64,
        'Path Complexity Metrics': min(features.get('path_length', 0) / 100, 1.0) * 0.57,
        'Information Entropy Analysis': features.get('entropy', 0) / 8 * 0.69,
        'Linguistic Pattern Recognition': features.get('vowel_ratio', 0) * 0.43
    }
    
    df = pd.DataFrame(list(feature_impacts.items()), columns=['Feature', 'Impact Score'])
    df = df.sort_values('Impact Score', ascending=False)
    return df

# Corrected OpenAI API calling function
def analyze_url_with_openai(url: str, client: OpenAI) -> str:
    """Enterprise-grade URL analysis using OpenAI's advanced models"""
    if not client:
        return "üîí Enterprise API access required. Contact system administrator for authentication credentials."
    
    try:
        features = extract_url_features(url)
        
        system_prompt = """You are CyberSentinel Pro, an enterprise-grade cybersecurity AI specializing in advanced threat detection and phishing analysis. 
        Provide professional, detailed analysis suitable for enterprise security teams."""
        
        user_prompt = f"""
        üîç ENTERPRISE THREAT ANALYSIS REQUEST
        
        Target URL: {url}
        
        Please act as the **sole decision-maker** and judge based on the data provided:
        1. üéØ THREAT CLASSIFICATION (MALICIOUS/BENIGN) ‚Äî you decide definitively
        2. üìà CONFIDENCE ASSESSMENT (98.0000‚Äì99.9999%)
        3. Make sure the URL is analyzed with the highest level of scrutiny and professionalism.
        4. Take proper care if the the URL is a phishing attempt or not.
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=600,
            temperature=0.2
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"üö® Enterprise API Error: {str(e)}\n\nüìä Falling back to enterprise rule-based analysis engine..."

def enhanced_predict(url: str, client: OpenAI = None) -> Tuple[str, float, str]:
    """AI-driven prediction where OpenAI model makes the entire decision"""
    if not client:
        return "‚ö†Ô∏è UNVERIFIED", 98.0000, "üîí Enterprise AI analysis requires authentication"
    
    # Get AI analysis
    ai_analysis = analyze_url_with_openai(url, client)
    
    # Extract classification and confidence directly from AI response
    classification_match = re.search(r"THREAT CLASSIFICATION.*?:.*?(MALICIOUS|BENIGN)", ai_analysis, re.IGNORECASE)
    confidence_match = re.search(r"CONFIDENCE ASSESSMENT.*?:.*?(\d{2}\.\d{4})%", ai_analysis)
    
    if classification_match:
        classification = classification_match.group(1).strip().upper()
        prediction = "üö® MALICIOUS" if classification == "MALICIOUS" else "‚úÖ LEGITIMATE"
    else:
        prediction = "‚ö†Ô∏è UNVERIFIED"
    
    if confidence_match:
        confidence = float(confidence_match.group(1))
    else:
        confidence = 98.0000  # Fallback if AI does not specify

    # Log analysis
    st.session_state.analysis_logs.append({
        'timestamp': datetime.now(),
        'url': url,
        'prediction': prediction.replace('üö® ', '').replace('‚úÖ ', ''),
        'confidence': round(confidence, 4),
        'risk_score': 0.0,  # Not used anymore
        'analysis_time': round(random.uniform(0.8, 1.9), 3)
    })
    
    return prediction, confidence, ai_analysis


# Enhanced visualization functions
def create_feature_plot(df: pd.DataFrame):
    """Create professional feature importance visualization"""
    fig = px.bar(
        df, 
        x='Impact Score', 
        y='Feature',
        orientation='h',
        title='üî¨ Advanced Feature Impact Analysis - CyberSentinel Pro',
        color='Impact Score',
        color_continuous_scale='RdYlBu_r',
        labels={'Impact Score': 'Threat Impact Score', 'Feature': 'Security Features'}
    )
    fig.update_layout(
        height=600, 
        yaxis={'categoryorder':'total ascending'},
        font=dict(family="Arial, sans-serif", size=12),
        title_font_size=16
    )
    return fig

def create_enterprise_risk_gauge(confidence: float, prediction: str):
    """Create visually enhanced enterprise risk gauge"""
    def gradient_color(c):
        # Map confidence to a green-red gradient
        r = int(255 * (c - 98) / 2)
        g = int(255 * (100 - c) / 2)
        return f"rgb({r},{g},80)"

    color = gradient_color(confidence)

    title_text = f"üéØ {'‚úÖ' if 'LEGITIMATE' in prediction else 'üö®'} {prediction} CONFIDENCE"

    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=confidence,
        delta={'reference': 95, 'increasing': {'color': "red"}, 'position': "top"},
        number={'suffix': "%", 'font': {'size': 36, 'color': "#003366"}},
        title={'text': title_text, 'font': {'size': 18, 'color': "#003366"}},
        gauge={
            'axis': {'range': [0, 100], 'tickwidth': 1.5, 'tickcolor': "#003366"},
            'bar': {'color': color, 'thickness': 0.25},
            'bgcolor': "white",
            'borderwidth': 2,
            'bordercolor': "gray",
            'steps': [
                {'range': [0, 90], 'color': '#f8f9fa'},
                {'range': [90, 95], 'color': '#ffe066'},
                {'range': [95, 98], 'color': '#faa307'},
                {'range': [98, 100], 'color': '#d00000'}
            ],
            'threshold': {
                'line': {'color': "#212529", 'width': 4},
                'thickness': 0.8,
                'value': 99
            }
        }
    ))

    fig.update_layout(
        height=300,
        paper_bgcolor="rgba(0,0,0,0)",
        font={'family': "Arial", 'color': "#003366"}
    )
    return fig


def get_current_stats():
    """Get current day statistics"""
    today = datetime.now().strftime('%Y-%m-%d')
    if today not in st.session_state.daily_stats:
        st.session_state.daily_stats[today] = {
            'urls_analyzed': 0,
            'threats_detected': 0,
            'avg_response_time': 1.2,
            'system_uptime': 99.7
        }
    
    # Count today's logs
    today_logs = [log for log in st.session_state.analysis_logs if log['timestamp'].strftime('%Y-%m-%d') == today]
    threats_today = len([log for log in today_logs if log['prediction'] == 'Phishing'])
    
    st.session_state.daily_stats[today]['urls_analyzed'] = len(today_logs)
    st.session_state.daily_stats[today]['threats_detected'] = threats_today
    
    return st.session_state.daily_stats[today]

# Administrator login function
def admin_login_section():
    """Handle administrator login with decreasing attempts"""
    st.subheader("üîê Administrator Authentication Required")
    st.warning("‚ö†Ô∏è Administrative privileges required to modify system configuration")
    
    with st.form("admin_login"):
        col1, col2 = st.columns(2)
        with col1:
            username = st.text_input("üë§ Administrator Username:")
        with col2:
            password = st.text_input("üîë Password:", type="password")
        
        submit = st.form_submit_button("üöÄ Authenticate")
        
        if submit:
            st.session_state.admin_attempts -= 1
            
            if st.session_state.admin_attempts <= 0:
                st.error("üö® ACCOUNT LOCKED: Maximum authentication attempts exceeded. Contact system administrator.")
                st.stop()
            else:
                st.error(f"‚ùå Invalid credentials. Attempts remaining: {st.session_state.admin_attempts}")
                st.warning("‚ö†Ô∏è Unauthorized access attempts are logged and monitored.")
    
    return False

# Main application
def main():
    # Header with company branding
    st.markdown("""
    <div style='text-align: center; padding: 1rem; background: linear-gradient(90deg, #1e3c72 0%, #2a5298 100%); color: white; margin-bottom: 2rem;'>
        <h1>Phishing Detection v1.6</h1>
    </div>
    """, unsafe_allow_html=True)
    
    # Initialize OpenAI client
    api_key = st.secrets["openai"]["OPENAI_API_KEY"]
    client = OpenAI(api_key=api_key)
    
    # Sidebar navigation with professional styling
    st.sidebar.markdown("### üéõÔ∏è System Navigation")
    tabs = st.sidebar.radio(
        "Select Module:", 
        ["üîç Threat Analysis", "üìä Batch Processing", "üìà Intelligence Analytics", "‚öôÔ∏è System Configuration"],
        help="Navigate through different modules of CyberSentinel Pro"
    )
    
    if tabs == "üîç Threat Analysis":
        st.header("üîç Advanced Threat Analysis Engine")
        
        url = st.text_input("üéØ Enter URL for comprehensive security analysis:", 
                           placeholder="https://example-domain.com/suspicious-path",
                           help="Submit any URL for deep security analysis")
        
        col1, col2 = st.columns([1, 3])
        with col1:
            analyze_btn = st.button("üöÄ ANALYZE THREAT", type="primary", use_container_width=True)
        with col2:
            if not client:
                st.warning("‚ö†Ô∏è Enterprise AI analysis requires valid API credentials")
        
        if analyze_btn and url:
            with st.spinner("üîç Performing deep security analysis..."):
                time.sleep(random.uniform(1.2, 2.8))  # Realistic processing time
                prediction, confidence, ai_analysis = enhanced_predict(url, client)
                features_df = generate_shap_analysis(url)
            
            # Results display with professional layout
            st.markdown("---")
            st.subheader("üìã Analysis Results")
            
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.plotly_chart(create_enterprise_risk_gauge(confidence, prediction), use_container_width=True)
                
                # Detailed feature extraction
                st.markdown("#### üî¨ Extracted Security Features")
                features = extract_url_features(url)
                
                with st.expander("üìä Technical Analysis Details"):
                    for key, value in features.items():
                        icon = "‚ö†Ô∏è" if isinstance(value, bool) and value else "‚úÖ" if isinstance(value, bool) else "üìä"
                        st.text(f"{icon} {key.replace('_', ' ').title()}: {value}")
                
                # Risk assessment summary
                st.markdown("#### üéØ Risk Assessment")
                risk_level = "HIGH" if "MALICIOUS" in prediction else "LOW"
                risk_color = "üî¥" if risk_level == "HIGH" else "üü¢"
                st.markdown(f"**Risk Level:** {risk_color} {risk_level}")
                st.markdown(f"**Confidence:** {confidence:.4f}%")
                st.markdown(f"**Analysis Time:** {random.uniform(0.8, 1.9):.3f}s")
            
            with col2:
                st.markdown("#### ü§ñ Enterprise AI Analysis")
                if "Enterprise API Error" in ai_analysis:
                    st.warning("üîí Advanced AI analysis requires enterprise authentication")
                    st.code(ai_analysis, language="text")
                else:
                    st.markdown(ai_analysis)
                
                # Recommendation engine
                st.markdown("#### üõ°Ô∏è Security Recommendations")
                if "MALICIOUS" in prediction:
                    st.error("""
                    **IMMEDIATE ACTIONS REQUIRED:**
                    - üö´ Block URL across all enterprise endpoints
                    - üìß Alert security team and stakeholders
                    - üîç Investigate potential data exposure
                    - üìù Document incident for compliance reporting
                    """)
                else:
                    st.success("""
                    **SECURITY STATUS: CLEARED**
                    - ‚úÖ URL appears legitimate and safe
                    - üîç Continue standard monitoring protocols
                    - üìä Log analysis for trend identification
                    """)
            
            # Feature importance visualization
            st.markdown("---")
            st.subheader("üìà Advanced Feature Impact Analysis")
            st.plotly_chart(create_feature_plot(features_df), use_container_width=True)
    
    elif tabs == "üìä Batch Processing":
        st.header("üìä Enterprise Batch Processing Engine")
        
        uploaded_file = st.file_uploader("üìÅ Upload Enterprise URL Dataset (CSV Format)", 
                                       type=['csv'],
                                       help="CSV must contain 'url' column for batch analysis")
        
        if uploaded_file:
            try:
                df = pd.read_csv(uploaded_file)
                
                if 'url' not in df.columns:
                    st.error("‚ùå Invalid CSV format: 'url' column required")
                    return
                
                st.success(f"‚úÖ Dataset loaded: {len(df)} URLs queued for analysis")
                st.dataframe(df.head(10))
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    batch_mode = st.selectbox("Analysis Mode:", ["Standard", "Deep Scan", "Express"])
                with col2:
                    parallel_threads = st.number_input("Parallel Threads:", 1, 10, 4)
                with col3:
                    priority = st.selectbox("Priority Level:", ["Normal", "High", "Critical"])
                
                if st.button("üöÄ START BATCH ANALYSIS", type="primary"):
                    results = []
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    time_estimate = st.empty()
                    
                    start_time = time.time()
                    
                    for i, row in df.iterrows():
                        elapsed = time.time() - start_time
                        remaining = (elapsed / (i + 1)) * (len(df) - i - 1) if i > 0 else 0
                        
                        status_text.text(f"üîç Analyzing [{i+1}/{len(df)}]: {row['url'][:60]}...")
                        time_estimate.text(f"‚è±Ô∏è Estimated time remaining: {remaining:.1f}s")
                        
                        prediction, confidence, _ = enhanced_predict(row['url'], client)
                        
                        results.append({
                            'URL': row['url'],
                            'Classification': prediction.replace('üö® ', '').replace('‚úÖ ', ''),
                            'Confidence': f"{confidence:.4f}%",
                            'Risk_Score': f"{random.uniform(0.01, 0.99):.4f}",
                            'Analysis_Time': f"{random.uniform(0.5, 2.1):.3f}s",
                            'Threat_Level': 'CRITICAL' if confidence > 99.5 and 'MALICIOUS' in prediction else 'HIGH' if confidence > 99.0 and 'MALICIOUS' in prediction else 'MEDIUM' if 'MALICIOUS' in prediction else 'LOW'
                        })
                        
                        progress_bar.progress((i + 1) / len(df))
                        time.sleep(random.uniform(0.1, 0.3))  # Realistic processing delay
                    
                    results_df = pd.DataFrame(results)
                    
                    # Analysis complete
                    st.success("‚úÖ Batch analysis completed successfully!")
                    
                    # Executive summary
                    col1, col2, col3, col4, col5 = st.columns(5)
                    with col1:
                        st.metric("üìä Total Analyzed", len(results_df))
                    with col2:
                        malicious_count = len(results_df[results_df['Classification'] == 'MALICIOUS'])
                        st.metric("üö® Threats Detected", malicious_count)
                    with col3:
                        avg_confidence = sum([float(r['Confidence'].replace('%', '')) for r in results]) / len(results)
                        st.metric("üéØ Avg Confidence", f"{avg_confidence:.2f}%")
                    with col4:
                        total_time = sum([float(r['Analysis_Time'].replace('s', '')) for r in results])
                        st.metric("‚è±Ô∏è Total Time", f"{total_time:.1f}s")
                    with col5:
                        critical_threats = len(results_df[results_df['Threat_Level'] == 'CRITICAL'])
                        st.metric("‚ö†Ô∏è Critical Threats", critical_threats)
                    
                    # Display results table
                    st.markdown("---")
                    st.subheader("üìã Batch Analysis Results")
                    st.dataframe(results_df, use_container_width=True)
                    
                    # Export options
                    col1, col2 = st.columns(2)
                    with col1:
                        csv = results_df.to_csv(index=False)
                        st.download_button("üì• Download CSV Report", csv, "batch_analysis_results.csv", "text/csv")
                    with col2:
                        if st.button("üìß Email Report to Security Team"):
                            st.success("üìß Report queued for delivery to security@company.com")
                    
                    # Threat distribution visualization
                    threat_dist = results_df['Threat_Level'].value_counts()
                    fig = px.pie(values=threat_dist.values, names=threat_dist.index, 
                               title="üéØ Threat Level Distribution")
                    st.plotly_chart(fig, use_container_width=True)
                    
            except Exception as e:
                st.error(f"‚ùå Error processing file: {str(e)}")
    
    elif tabs == "üìà Intelligence Analytics":
        st.header("üìà Advanced Intelligence Analytics")
        
        # Time range selector
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input("üìÖ Start Date", datetime.now() - timedelta(days=30))
        with col2:
            end_date = st.date_input("üìÖ End Date", datetime.now())
        
        # Filter logs by date range
        filtered_logs = [
            log for log in st.session_state.analysis_logs 
            if start_date <= log['timestamp'].date() <= end_date
        ]
        
        if not filtered_logs:
            st.warning("‚ö†Ô∏è No data available for selected date range")
            return
        
        # Convert to DataFrame for analysis
        df_logs = pd.DataFrame(filtered_logs)
        df_logs['date'] = df_logs['timestamp'].dt.date
        
        # Key metrics
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            total_urls = len(df_logs)
            st.metric("üîç Total URLs Analyzed", total_urls)
        with col2:
            threats_detected = len(df_logs[df_logs['prediction'] == 'Phishing'])
            st.metric("üö® Threats Detected", threats_detected)
        with col3:
            detection_rate = (threats_detected / total_urls * 100) if total_urls > 0 else 0
            st.metric("üéØ Detection Rate", f"{detection_rate:.2f}%")
        with col4:
            avg_confidence = df_logs['confidence'].mean()
            st.metric("üìä Avg Confidence", f"{avg_confidence:.2f}%")
        
        st.markdown("---")
        
        # Analytics visualizations
        col1, col2 = st.columns(2)
        
        with col1:
            # Daily threat trend
            daily_threats = df_logs[df_logs['prediction'] == 'Phishing'].groupby('date').size().reset_index(name='threats')
            fig = px.line(daily_threats, x='date', y='threats', 
                         title='üìà Daily Threat Detection Trend',
                         markers=True)
            fig.update_layout(xaxis_title="Date", yaxis_title="Threats Detected")
            st.plotly_chart(fig, use_container_width=True)
            
            # Confidence distribution
            fig = px.histogram(df_logs, x='confidence', nbins=20, 
                              title='üìä Confidence Score Distribution')
            fig.update_layout(xaxis_title="Confidence %", yaxis_title="Count")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Prediction distribution
            pred_dist = df_logs['prediction'].value_counts()
            fig = px.pie(values=pred_dist.values, names=pred_dist.index,
                        title='üîç Classification Distribution')
            st.plotly_chart(fig, use_container_width=True)
            
            # Response time analysis
            fig = px.box(df_logs, y='analysis_time', 
                        title='‚ö° Analysis Time Distribution')
            fig.update_layout(yaxis_title="Response Time (seconds)")
            st.plotly_chart(fig, use_container_width=True)
        
        # Detailed analytics table
        st.markdown("---")
        st.subheader("üìã Detailed Analysis Logs")
        
        # Search and filter options
        col1, col2, col3 = st.columns(3)
        with col1:
            search_url = st.text_input("üîç Search URLs:", placeholder="Enter URL to search")
        with col2:
            filter_prediction = st.selectbox("Filter by Classification:", 
                                           ["All", "Phishing", "Legitimate"])
        with col3:
            min_confidence = st.slider("Minimum Confidence %:", 0.0, 100.0, 0.0)
        
        # Apply filters
        display_logs = df_logs.copy()
        if search_url:
            display_logs = display_logs[display_logs['url'].str.contains(search_url, case=False)]
        if filter_prediction != "All":
            display_logs = display_logs[display_logs['prediction'] == filter_prediction]
        display_logs = display_logs[display_logs['confidence'] >= min_confidence]
        
        # Format for display
        display_logs['timestamp'] = display_logs['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')
        display_logs = display_logs[['timestamp', 'url', 'prediction', 'confidence', 'risk_score', 'analysis_time']]
        display_logs.columns = ['Timestamp', 'URL', 'Classification', 'Confidence %', 'Risk Score', 'Analysis Time']
        
        st.dataframe(display_logs, use_container_width=True)
        
        # Export filtered data
        if len(display_logs) > 0:
            csv = display_logs.to_csv(index=False)
            st.download_button("üì• Export Filtered Data", csv, 
                             f"filtered_analysis_{start_date}_{end_date}.csv", "text/csv")
    
    elif tabs == "‚öôÔ∏è System Configuration":
        # Check admin authentication
        if not admin_login_section():
            return
        
        st.header("‚öôÔ∏è Enterprise System Configuration")
        st.warning("üîí Administrator access required - Authentication pending")
        
        # Mock configuration options (since admin login always fails)
        with st.expander("üîß Detection Engine Settings", expanded=False):
            st.slider("Threat Detection Sensitivity", 0.1, 1.0, 0.8, disabled=True)
            st.selectbox("Analysis Mode", ["Standard", "Aggressive", "Conservative"], disabled=True)
            st.number_input("Batch Processing Threads", 1, 20, 8, disabled=True)
        
        with st.expander("üåê API Configuration", expanded=False):
            st.text_input("OpenAI API Endpoint", value="https://api.openai.com/v1", disabled=True)
            st.number_input("Request Timeout (seconds)", 5, 60, 30, disabled=True)
            st.selectbox("Default Model", ["gpt-4", "gpt-3.5-turbo"], disabled=True)
        
        with st.expander("üìä Monitoring & Alerts", expanded=False):
            st.checkbox("Email Alerts for Critical Threats", value=True, disabled=True)
            st.text_input("Alert Recipients", value="security@company.com", disabled=True)
            st.number_input("Alert Threshold (threats/hour)", 1, 100, 10, disabled=True)
        
        st.info("üîê Contact system administrator for configuration changes")

# Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666; padding: 1rem;'>
        <p>Phishing Detection v1.6 | Test Cluster 3 | CPU 2GHz VRAM 2GB</p>
        <p>Copyright 2025 Meander Softwares Pvt. Ltd. | All Rights Reserved </p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()